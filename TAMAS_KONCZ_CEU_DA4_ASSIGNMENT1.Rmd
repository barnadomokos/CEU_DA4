---
title: "DA4 -  Assignment 1"
author: "Tamas Koncz"
date: '2018-02-11'
output:
  html_document:
    df_print: paged
  html_notebook:
    df_print: paged
---

```{r, message=FALSE}
require(data.table)
require(ggplot2)
require(gridExtra)
require(caret)

options(scipen = 999)

theme_set(theme_minimal())   # globally set ggplot theme

set.seed(1234)
RMSE <- function(x, true_x) sqrt(mean((x - true_x)^2))
```


```{r}
data <- fread("airbnb_london_workfile.csv",
              stringsAsFactors = FALSE)
```

##### Code snippet for selecting random borough: 

```{r}
boroughs <- data[, .(count = .N, 
                     avg_price = mean(price)), 
                 keyby = f_neighbourhood_cleansed][order(-count)]

boroughs[, borough := factor(f_neighbourhood_cleansed, 
                             levels = boroughs[order(count)][, f_neighbourhood_cleansed])]
boroughs[, f_neighbourhood_cleansed := NULL]

# randomly picking an area > 1000
set.seed(93) #for reproducibility
selected <- sample(boroughs[count > 1000]$borough, 1)

```

```{r, fig.align= 'center', fig.width= 10}
max_count <- boroughs[, max(count)]
max_avg_price <- boroughs[, max(avg_price)]

boroughs[borough == selected, ] #TODO: make this bold on the chart

ggplot(data = boroughs) + 
  geom_bar(data = boroughs[borough == selected], aes(x = borough, y = 6000), fill = "lightblue",  stat = "identity") +
  geom_point(aes(x = borough, y = count, color = "# of Observations"), shape = 20, size = 2) +
  geom_segment(aes(x = borough, y = count, xend = borough, yend =0, color = "# of Observations")) + 
  geom_point(aes(x = borough, y = avg_price * (max_count/max_avg_price), color = "Avg. Price"), shape = 4, size = 2) + 
  scale_y_continuous(limits = c(0,6000), sec.axis = sec_axis(~./(max_count/max_avg_price), name = "Avg. Price")) + 
  scale_color_manual(name = "Legend", values = c("# of Observations" = "tomato", "Avg. Price" = "darkblue")) + 
  guides(color=guide_legend(override.aes=list(shape=15))) +
  labs(y = "# of Observations", x = "Borough") +
  coord_flip()
```

```{r}
london <- copy(data)
rm(data)
rm(boroughs)
rm(max_count)
rm(max_avg_price)
```

```{r}
#handling NAs
missing_values <- as.data.table(t(london[, lapply(.SD, function(x) sum(is.na(x))), .SDcols = names(london)]), keep.rownames=TRUE)
setnames(missing_values, c("variable", "NA.Count"))

missing_values[order(-NA.Count)][1:10]

#no significance
ggplot(data= london, aes(x = n_review_scores_rating, y = price)) + geom_point() + geom_smooth()

# assumption: when cleaning_fee is missing, it's actually zero
london[, cleaning_fee := ifelse(is.na(usd_cleaning_fee), 0, usd_cleaning_fee)]

#step1: drop variables with lots of NAs
london[, c("usd_cleaning_fee", 
           "n_review_scores_rating",
           "n_reviews_per_month",
           "n_days_since",
           "p_host_response_rate") := NULL]


#step2: drop non-complete cases
london <- london[complete.cases(london)]
```

```{r}
# creating log price
london[, log_price:= log(price)]

# creating a total score for dummy variables. very much simplified approach
london[, d_total := Reduce("+", .SD), .SDcols = names(london) %like% "^d_.*"]

# cleaning up factor variables / duplicated
london[, c("neighbourhood_cleansed", 
           "property_type", 
           "room_type", 
           "usd_price_day", 
           "cancellation_policy") := NULL]

factor_cols <- names(london)[names(london) %like% "^f_.*"]
london[, (factor_cols) := lapply(.SD, as.factor), .SDcols = factor_cols]
```



```{r}
rm(missing_values)
```


```{r}
#creating subset
kensington_chelsea <- london[f_neighbourhood_cleansed == selected]
```


```{r}
ggplot(data= london, aes(x = log_price)) + geom_histogram()
ggplot(data= kensington_chelsea, aes(x = log_price)) + geom_histogram()

# TODO: add reasoning for log transformation. two hist, not-log, common density, log

ggplot(data= london, aes(x = n_accommodates)) + geom_histogram()
ggplot(data= london, aes(x = n_accommodates, y = log_price)) + geom_point() + geom_smooth()

ggplot(data= london, aes(x = n_beds)) + geom_histogram()
ggplot(data= london, aes(x = n_beds, y = log_price)) + geom_point() + geom_smooth()
#transform both for deminishing returns?

# f_room_type
ggplot(data= london, aes(x = f_room_type)) + geom_bar()
ggplot(data= london, aes(x = f_room_type, y = log_price)) + geom_boxplot()

# f_cancellation_policy -> surprising result. correlation with sth else?
ggplot(data= london, aes(x = f_cancellation_policy)) + geom_bar()
ggplot(data= london, aes(x = f_cancellation_policy, y = log_price)) + geom_boxplot()

#d_breakfast -> no big impact. add d_ to TOTAL?
ggplot(data= london, aes(x = d_breakfast)) + geom_bar()
ggplot(data= london, aes(x = factor(d_breakfast), y = log_price)) + geom_boxplot()

#n_number_of_reviews
ggplot(data= london, aes(x = n_number_of_reviews)) + geom_histogram()
ggplot(data= kensington_chelsea, aes(x = n_number_of_reviews, y = log_price)) + geom_point() + geom_smooth()

#n_minimum_nights --> some outliers, handle
ggplot(data= london, aes(x = n_minimum_nights)) + geom_histogram()
ggplot(data= london, aes(x = n_minimum_nights, y = log_price)) + geom_point() + geom_smooth()

#f_property_type --> some interaction with other variables, eg. room type?
ggplot(data= london, aes(x = f_property_type)) + geom_bar()
ggplot(data= london, aes(x = f_property_type, y = log_price)) + geom_boxplot()

# usd_cleaning_fee --> model non-linearity?
ggplot(data= london, aes(x = cleaning_fee)) + geom_histogram()
ggplot(data= london, aes(x = cleaning_fee, y = log_price)) + geom_point() + geom_smooth()


# d_total
ggplot(data= london, aes(x = d_total)) + geom_histogram()
ggplot(data= london, aes(x = d_total, y = log_price)) + geom_point() + geom_smooth()
```


Next step is to create separate datasets for model training and performance evaluations (same method was followed for the Kensington and Chelsea subsample): 

```{r}
training_ratio <- 0.7

set.seed(93) #for reproducibility
train_indices <- createDataPartition(y = london[["log_price"]],
                                     times = 1,
                                     p = training_ratio,
                                     list = FALSE)
london_train <- london[train_indices, ]
london_test <- london[-train_indices, ]
```

```{r, include= FALSE}
set.seed(93) #for reproducibility
train_indices <- createDataPartition(y = kensington_chelsea[["log_price"]],
                                     times = 1,
                                     p = training_ratio,
                                     list = FALSE)
kensington_chelsea_train <- kensington_chelsea[train_indices, ]
kensington_chelsea_test <- kensington_chelsea[-train_indices, ]
```
 
 
Setting the control parameters for 10-fold CV:
```{r}
fit_control <- trainControl(method = "cv", number = 10)
```

```{r}
#base  model - just using n_accomodates

set.seed(93) #for reproducibility
model_1_london <- train(log_price ~ n_accommodates, 
                   data = london_train, 
                   method = "lm", 
                   trControl = fit_control)
model_1_london$results[["RMSE"]]
```

```{r}
#base  model - just using n_accomodates

set.seed(93) #for reproducibility
model_1_kensington_chelsea_train <- train(log_price ~ n_accommodates, 
                   data = kensington_chelsea_train, 
                   method = "lm", 
                   trControl = fit_control)
model_1_kensington_chelsea_train$results[["RMSE"]]
```


```{r}
#simple model - using multiple predictor variables

set.seed(93) #for reproducibility
model_2_london <- train(log_price ~ n_accommodates + n_beds + n_bathrooms + 
                          f_property_type + f_room_type + f_bed_type, 
                   data = london_train, 
                   method = "lm", 
                   trControl = fit_control)
model_2_london$results[["RMSE"]]
```

```{r, include= FALSE}

set.seed(93) #for reproducibility
model_2_kensington_chelsea <- train(log_price ~ n_accommodates + n_beds + n_bathrooms +
                                            f_property_type + f_room_type + f_bed_type, 
                                          data = kensington_chelsea_train, 
                                          method = "lm",
                                          trControl = fit_control)
model_2_kensington_chelsea$results[["RMSE"]]
```


```{r}
tune_grid <- expand.grid("alpha" = 1,
                             "lambda" = seq(0, 0.015, 0.001))
```


```{r}
#l <- sapply(kensington_chelsea_train, function(x) is.factor(x))
#m <- kensington_chelsea_train[, ..l]
#str(m)
#sapply(kensington_chelsea_train, function(x) length(unique(x)))
```


```{r}
#full model - most complexity, all variables

set.seed(93) #for reproducibility
model_4_london <- train(log_price ~ . -price -d_total -f_neighbourhood_cleansed -d_washerdryer -d_freeparkingonstreet -d_paidparkingoffpremises, 
                    data = london_train, 
                    method = "glmnet",
                    preProcess = c("center", "scale"),
                    tuneGrid = tune_grid,
                    metric = "RMSE",
                    trControl = fit_control)

model_4_london$results[["RMSE"]]
```


```{r}
#full model - most complexity, all variables

set.seed(93) #for reproducibility
model_4_kensington_chelsea <- train(log_price ~ . -price -d_total -f_neighbourhood_cleansed -d_washerdryer -d_freeparkingonstreet -d_paidparkingoffpremises, 
                    data = kensington_chelsea_train, 
                    method = "glmnet",
                    preProcess = c("center", "scale"),
                    tuneGrid = tune_grid,
                    metric = "RMSE",
                    trControl = fit_control)

model_4_kensington_chelsea$results[["RMSE"]]
```

